{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate split from root\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "np.random.seed(seed=2358)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# os.chdir(\"/home/data/workspace/heqi/monogastroendo/\")\n",
    "\n",
    "root=\"/home/data/workspace/heqi/monogastroendo/rect_c3vd_data/\"\n",
    "\n",
    "folders = glob.glob(root+\"*\")\n",
    "folders.sort()\n",
    "splits = [['cecum_t1_a_under_review/c1v1',\n",
    "            'cecum_t1_b_under_review/c1v3',\n",
    "            'cecum_t2_a_under_review/c2v1',\n",
    "            'cecum_t2_b_under_review/c2v2',\n",
    "            'cecum_t2_c_under_review/c2v3',\n",
    "            'cecum_t3_a_under_review/c3v2',\n",
    "            'desc_t4_a_under_review/d4v2',\n",
    "            'sigmoid_t1_a_under_review/s1v3',\n",
    "            'sigmoid_t2_a_under_review/s2v1',\n",
    "            'trans_t1_a_under_review/t1v1',\n",
    "            'trans_t1_b_under_review/t1v3',\n",
    "            'trans_t2_a_under_review/t2v1',\n",
    "            'trans_t2_b_under_review/t2v2',\n",
    "            'trans_t2_c_under_review/t2v3',\n",
    "            'trans_t3_a_under_review/t3v2',\n",
    "            'trans_t3_b_under_review/t3v3',],\n",
    "          ['cecum_t4_a_under_review/c4v2',\n",
    "            'cecum_t4_b_under_review/c4v3',\n",
    "            'sigmoid_t3_a_under_review/s3v1',\n",
    "            'sigmoid_t3_b_under_review/s3v2',\n",
    "            'trans_t4_a_under_review/t4v1',\n",
    "            'trans_t4_b_under_review/t4v3']]\n",
    "\n",
    "def check_valid_input(splits):\n",
    "    for split in splits:\n",
    "        for folder in split:\n",
    "            src = os.path.join(root, folder)\n",
    "            assert(os.path.exists(src))\n",
    "\n",
    "def load_split(folders, skip=5):\n",
    "    outputs = []\n",
    "    for folder in folders:\n",
    "        files = glob.glob(root+folder+\"/*_color.png\")\n",
    "        for i in range(0, len(files) - 2*skip):\n",
    "            line = [folder]\n",
    "            for j in range(3):\n",
    "                line.append(f\"{i+j*skip}\")\n",
    "                fname = f\"{root+folder}/{i+j*skip}_color.png\"\n",
    "                assert(os.path.exists(fname))\n",
    "            outputs.append(\" \".join(line))\n",
    "    return outputs\n",
    "\n",
    "def check_opticflow(prvs, next):\n",
    "    import cv2\n",
    "    prvs = cv2.cvtColor(prvs, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert the frame to grayscale\n",
    "    next = cv2.cvtColor(next, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow using the Lucas-Kanade method\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    return flow\n",
    "\n",
    "\n",
    "check_valid_input(splits)\n",
    "\n",
    "train = load_split(splits[0])\n",
    "test = load_split(splits[1])\n",
    "\n",
    "with open(\"train_files.txt\", \"w\") as f:\n",
    "    for line in train:\n",
    "        f.write(line+\"\\n\")\n",
    "\n",
    "with open(\"val_files.txt\", \"w\") as f:\n",
    "    for line in test:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.180983 -23.331966 0.42609474 (1080, 1350, 2)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def check_opticflow(prvs, next):\n",
    "    prvs = cv2.cvtColor(prvs, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert the frame to grayscale\n",
    "    next = cv2.cvtColor(next, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate optical flow using the Lucas-Kanade method\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    return flow\n",
    "\n",
    "def test_check_opticflow():\n",
    "    root = \"/home/data/workspace/heqi/monogastroendo/rect_c3vd_data/\"\n",
    "    folder = \"cecum_t1_a_under_review/c1v1\"\n",
    "    skip=16\n",
    "    i=0\n",
    "    prvs = f\"{root+folder}/{i+0*skip}_color.png\"\n",
    "    next = f\"{root+folder}/{i+1*skip}_color.png\"\n",
    "    prvs = cv2.imread(prvs)\n",
    "    next = cv2.imread(next)\n",
    "    flow = check_opticflow(prvs, next)\n",
    "    \n",
    "    return flow\n",
    "\n",
    "flow = test_check_opticflow()\n",
    "\n",
    "print(flow.max(), flow.min(), np.abs(flow).mean(), flow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net exists\n",
      "tensor(8.3037, device='cuda:0')\n",
      "tensor(8.2939, device='cuda:0')\n",
      "tensor(7.7998, device='cuda:0')\n",
      "tensor(8.2927, device='cuda:0')\n",
      "tensor(8.2553, device='cuda:0')\n",
      "tensor(8.2507, device='cuda:0')\n",
      "tensor(8.5285, device='cuda:0')\n",
      "tensor(9.2108, device='cuda:0')\n",
      "tensor(9.1012, device='cuda:0')\n",
      "tensor(8.1310, device='cuda:0')\n",
      "tensor(7.8676, device='cuda:0')\n",
      "tensor(8.6148, device='cuda:0')\n",
      "tensor(8.0486, device='cuda:0')\n",
      "tensor(8.4997, device='cuda:0')\n",
      "tensor(8.8880, device='cuda:0')\n",
      "tensor(8.4974, device='cuda:0')\n",
      "tensor(8.7938, device='cuda:0')\n",
      "tensor(8.1053, device='cuda:0')\n",
      "tensor(8.2620, device='cuda:0')\n",
      "tensor(8.2682, device='cuda:0')\n",
      "tensor(8.3271, device='cuda:0')\n",
      "tensor(7.8326, device='cuda:0')\n",
      "tensor(7.9617, device='cuda:0')\n",
      "tensor(7.5511, device='cuda:0')\n",
      "tensor(7.5976, device='cuda:0')\n",
      "tensor(7.2175, device='cuda:0')\n",
      "tensor(7.2931, device='cuda:0')\n",
      "tensor(7.3074, device='cuda:0')\n",
      "tensor(7.3691, device='cuda:0')\n",
      "tensor(7.1795, device='cuda:0')\n",
      "tensor(6.7509, device='cuda:0')\n",
      "tensor(7.1133, device='cuda:0')\n",
      "tensor(6.8974, device='cuda:0')\n",
      "tensor(6.5855, device='cuda:0')\n",
      "tensor(6.3151, device='cuda:0')\n",
      "tensor(6.3751, device='cuda:0')\n",
      "tensor(6.4195, device='cuda:0')\n",
      "tensor(6.3338, device='cuda:0')\n",
      "tensor(6.0106, device='cuda:0')\n",
      "tensor(6.0709, device='cuda:0')\n",
      "tensor(5.8600, device='cuda:0')\n",
      "tensor(5.7784, device='cuda:0')\n",
      "tensor(5.5293, device='cuda:0')\n",
      "tensor(5.5129, device='cuda:0')\n",
      "tensor(5.2272, device='cuda:0')\n",
      "tensor(5.1997, device='cuda:0')\n",
      "tensor(4.9478, device='cuda:0')\n",
      "tensor(5.1073, device='cuda:0')\n",
      "tensor(4.7366, device='cuda:0')\n",
      "tensor(4.9695, device='cuda:0')\n",
      "tensor(4.8224, device='cuda:0')\n",
      "tensor(4.9606, device='cuda:0')\n",
      "tensor(4.7819, device='cuda:0')\n",
      "tensor(5.1232, device='cuda:0')\n",
      "tensor(5.2724, device='cuda:0')\n",
      "tensor(5.3643, device='cuda:0')\n",
      "tensor(6.1805, device='cuda:0')\n",
      "tensor(6.6285, device='cuda:0')\n",
      "tensor(7.5544, device='cuda:0')\n",
      "tensor(7.6113, device='cuda:0')\n",
      "tensor(7.7997, device='cuda:0')\n",
      "tensor(8.3664, device='cuda:0')\n",
      "tensor(8.5854, device='cuda:0')\n",
      "tensor(9.1176, device='cuda:0')\n",
      "tensor(9.5963, device='cuda:0')\n",
      "tensor(9.9561, device='cuda:0')\n",
      "tensor(9.7697, device='cuda:0')\n",
      "tensor(10.1636, device='cuda:0')\n",
      "tensor(10.4068, device='cuda:0')\n",
      "tensor(10.7620, device='cuda:0')\n",
      "tensor(10.8953, device='cuda:0')\n",
      "tensor(10.9098, device='cuda:0')\n",
      "tensor(10.9469, device='cuda:0')\n",
      "tensor(10.9125, device='cuda:0')\n",
      "tensor(10.7999, device='cuda:0')\n",
      "tensor(10.7796, device='cuda:0')\n",
      "tensor(10.5057, device='cuda:0')\n",
      "tensor(10.4241, device='cuda:0')\n",
      "tensor(10.5065, device='cuda:0')\n",
      "tensor(10.6199, device='cuda:0')\n",
      "tensor(10.4854, device='cuda:0')\n",
      "tensor(10.5631, device='cuda:0')\n",
      "tensor(10.2293, device='cuda:0')\n",
      "tensor(9.8612, device='cuda:0')\n",
      "tensor(9.5129, device='cuda:0')\n",
      "tensor(9.1069, device='cuda:0')\n",
      "tensor(8.2380, device='cuda:0')\n",
      "tensor(8.0669, device='cuda:0')\n",
      "tensor(7.1540, device='cuda:0')\n",
      "tensor(6.6051, device='cuda:0')\n",
      "tensor(6.1193, device='cuda:0')\n",
      "tensor(5.5887, device='cuda:0')\n",
      "tensor(4.8059, device='cuda:0')\n",
      "tensor(3.9366, device='cuda:0')\n",
      "tensor(3.5313, device='cuda:0')\n",
      "tensor(2.9591, device='cuda:0')\n",
      "tensor(2.4448, device='cuda:0')\n",
      "tensor(2.0014, device='cuda:0')\n",
      "tensor(1.5927, device='cuda:0')\n",
      "tensor(1.0946, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/data/workspace/heqi/monogastroendo/\")\n",
    "from layers import LoFTR\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from kornia_moons.viz import draw_LAF_matches\n",
    "\n",
    "\n",
    "def load_torch_image(fname):\n",
    "    img = K.image_to_tensor(cv2.resize(cv2.imread(fname), (320, 256)), False).float() /255.\n",
    "    img = K.color.bgr_to_rgb(img)\n",
    "    return img\n",
    "\n",
    "def check_correspondences(prvs, next, net=None, show=True):\n",
    "    prvs = load_torch_image(prvs).to(device)\n",
    "    next = load_torch_image(next).to(device)\n",
    "    cor = net(prvs, next)\n",
    "\n",
    "    if show:\n",
    "        mkpts0 = cor['keypoints0'].cpu().numpy()\n",
    "        mkpts1 = cor['keypoints1'].cpu().numpy()\n",
    "\n",
    "        print(\"kp0 has {} key points\".format(mkpts0.shape[0]))\n",
    "        print(\"kp1 has {} key points\".format(mkpts1.shape[0]))\n",
    "\n",
    "        draw_LAF_matches(\n",
    "            KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n",
    "                                        torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n",
    "                                        torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n",
    "\n",
    "            KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n",
    "                                        torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n",
    "                                        torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n",
    "            torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n",
    "            K.tensor_to_image(prvs),\n",
    "            K.tensor_to_image(next),\n",
    "            draw_dict={'inlier_color': (0.2, 1, 0.2),\n",
    "                    'tentative_color': None, \n",
    "                    'feature_color': (0.2, 0.5, 1), 'vertical': False})\n",
    "    \n",
    "    return cor\n",
    "\n",
    "def test_check_correspondences(net):\n",
    "    root = \"/home/data/workspace/heqi/monogastroendo/rect_c3vd_data/\"\n",
    "    folder = \"cecum_t1_a_under_review/c1v1\"\n",
    "    i=0\n",
    "    prvs = f\"{root+folder}/{i+0*skip}_color.png\"\n",
    "    next = f\"{root+folder}/{i+1*skip}_color.png\"\n",
    "    cor = check_correspondences(prvs, next, net=net, show=False)\n",
    "    \n",
    "    # print(cor)\n",
    "    mask = cor['confidence']>0.9\n",
    "    dist = cor['keypoints0'][mask] - cor['keypoints1'][mask]\n",
    "    # print(dist.mean())\n",
    "    \n",
    "    return cor\n",
    "\n",
    "\n",
    "def check_dist(net):\n",
    "    root = \"/home/data/workspace/heqi/monogastroendo/rect_c3vd_data/\"\n",
    "    folder = \"cecum_t1_a_under_review/c1v1\"\n",
    "    for i in range(100):\n",
    "        prvs = f\"{root+folder}/{i+0*skip}_color.png\"\n",
    "        next = f\"{root+folder}/{i+1*skip}_color.png\"\n",
    "        cor = check_correspondences(prvs, next, net=net, show=False)\n",
    "        \n",
    "        mask = cor['confidence']>0.9\n",
    "        dist = cor['keypoints0'][mask] - cor['keypoints1'][mask]\n",
    "        \n",
    "        print(dist.abs().mean())\n",
    "    \n",
    "\n",
    "skip=20\n",
    "device = torch.device(\"cuda\")\n",
    "try:\n",
    "    net\n",
    "    print('net exists')\n",
    "except NameError:\n",
    "    net = LoFTR().to(device)\n",
    "    print('net does not exist')\n",
    "    \n",
    "correspondences = test_check_correspondences(net)\n",
    "check_dist(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6457/6457 [13:06<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We filterd 1825 static frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2778/2778 [05:45<00:00,  8.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We filterd 557 static frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.chdir(\"/home/data/workspace/heqi/monogastroendo/\")\n",
    "from layers import LoFTR\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "from kornia_moons.viz import draw_LAF_matches\n",
    "\n",
    "# generate split from root\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import glob\n",
    "\n",
    "np.random.seed(seed=2358)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# os.chdir(\"/home/data/workspace/heqi/monogastroendo/\")\n",
    "\n",
    "root=\"/home/data/workspace/heqi/monogastroendo/rect_c3vd_data/\"\n",
    "\n",
    "folders = glob.glob(root+\"*\")\n",
    "folders.sort()\n",
    "splits = [['cecum_t1_a_under_review/c1v1',\n",
    "            'cecum_t1_b_under_review/c1v3',\n",
    "            'cecum_t2_a_under_review/c2v1',\n",
    "            'cecum_t2_b_under_review/c2v2',\n",
    "            'cecum_t2_c_under_review/c2v3',\n",
    "            'cecum_t3_a_under_review/c3v2',\n",
    "            'desc_t4_a_under_review/d4v2',\n",
    "            'sigmoid_t1_a_under_review/s1v3',\n",
    "            'sigmoid_t2_a_under_review/s2v1',\n",
    "            'trans_t1_a_under_review/t1v1',\n",
    "            'trans_t1_b_under_review/t1v3',\n",
    "            'trans_t2_a_under_review/t2v1',\n",
    "            'trans_t2_b_under_review/t2v2',\n",
    "            'trans_t2_c_under_review/t2v3',\n",
    "            'trans_t3_a_under_review/t3v2',\n",
    "            'trans_t3_b_under_review/t3v3',],\n",
    "          ['cecum_t4_a_under_review/c4v2',\n",
    "            'cecum_t4_b_under_review/c4v3',\n",
    "            'sigmoid_t3_a_under_review/s3v1',\n",
    "            'sigmoid_t3_b_under_review/s3v2',\n",
    "            'trans_t4_a_under_review/t4v1',\n",
    "            'trans_t4_b_under_review/t4v3']]\n",
    "\n",
    "def check_valid_input(splits):\n",
    "    for split in splits:\n",
    "        for folder in split:\n",
    "            src = os.path.join(root, folder)\n",
    "            assert(os.path.exists(src))\n",
    "\n",
    "\n",
    "def load_torch_image(fname):\n",
    "    img = K.image_to_tensor(cv2.resize(cv2.imread(fname), (320, 256)), False).float() /255.\n",
    "    img = K.color.bgr_to_rgb(img)\n",
    "    return img\n",
    "\n",
    "def check_correspondences(prvs, next, show=True):\n",
    "    prvs = load_torch_image(prvs).to(device)\n",
    "    next = load_torch_image(next).to(device)\n",
    "    cor = net(prvs, next)\n",
    "\n",
    "    if show:\n",
    "        mkpts0 = cor['keypoints0'].cpu().numpy()\n",
    "        mkpts1 = cor['keypoints1'].cpu().numpy()\n",
    "\n",
    "        print(\"kp0 has {} key points\".format(mkpts0.shape[0]))\n",
    "        print(\"kp1 has {} key points\".format(mkpts1.shape[0]))\n",
    "\n",
    "        draw_LAF_matches(\n",
    "            KF.laf_from_center_scale_ori(torch.from_numpy(mkpts0).view(1,-1, 2),\n",
    "                                        torch.ones(mkpts0.shape[0]).view(1,-1, 1, 1),\n",
    "                                        torch.ones(mkpts0.shape[0]).view(1,-1, 1)),\n",
    "\n",
    "            KF.laf_from_center_scale_ori(torch.from_numpy(mkpts1).view(1,-1, 2),\n",
    "                                        torch.ones(mkpts1.shape[0]).view(1,-1, 1, 1),\n",
    "                                        torch.ones(mkpts1.shape[0]).view(1,-1, 1)),\n",
    "            torch.arange(mkpts0.shape[0]).view(-1,1).repeat(1,2),\n",
    "            K.tensor_to_image(prvs),\n",
    "            K.tensor_to_image(next),\n",
    "            draw_dict={'inlier_color': (0.2, 1, 0.2),\n",
    "                    'tentative_color': None, \n",
    "                    'feature_color': (0.2, 0.5, 1), 'vertical': False})\n",
    "    \n",
    "    return cor\n",
    "\n",
    "def check_dist(prvs, next):\n",
    "    cor = check_correspondences(prvs, next, show=False)        \n",
    "    mask = cor['confidence']>0.5\n",
    "    dist = cor['keypoints0'][mask] - cor['keypoints1'][mask]\n",
    "\n",
    "    return dist.abs().mean()\n",
    "    \n",
    "\n",
    "def load_split(folders):\n",
    "    outputs = []\n",
    "    # static_frames = 0\n",
    "    for folder in folders:\n",
    "        files = glob.glob(root+folder+\"/*_color.png\")\n",
    "        for i in range(0, len(files) - 2*skip):\n",
    "            line = [folder]\n",
    "            fnames = []\n",
    "            for j in range(3):\n",
    "                line.append(f\"{i+j*skip}\")\n",
    "                fname = f\"{root+folder}/{i+j*skip}_color.png\"\n",
    "                fnames.append(fname)\n",
    "                assert(os.path.exists(fname))\n",
    "            # # skip static frames\n",
    "            # if check_dist(fnames[0], fnames[1]) < 1 or check_dist(fnames[1], fnames[2]) < 1:\n",
    "            #     static_frames += 1\n",
    "            #     continue\n",
    "            outputs.append(\" \".join(line))\n",
    "    # print(\"We filterd {} static frames\".format(static_frames))\n",
    "    return outputs\n",
    "\n",
    "def filter_staticframe(lines):\n",
    "    static_frames = 0\n",
    "    outputs = []\n",
    "    for line in tqdm.tqdm(lines):\n",
    "        folder = line.split(\" \")[0]\n",
    "        findex = line.split(\" \")[1:]\n",
    "        fnames = []\n",
    "        for j in range(3):\n",
    "            fname = f\"{root+folder}/{findex[j]}_color.png\"\n",
    "            fnames.append(fname)\n",
    "            assert(os.path.exists(fname))\n",
    "        # skip static frames\n",
    "        if check_dist(fnames[0], fnames[1]) < 1 or check_dist(fnames[1], fnames[2]) < 1:\n",
    "            static_frames += 1\n",
    "            # assert(static_frames / len(lines) < 0.2)\n",
    "        else:\n",
    "            outputs.append(line)\n",
    "    print(\"We filterd {} static frames\".format(static_frames))\n",
    "    return outputs\n",
    "\n",
    "skip=20\n",
    "device = torch.device(\"cuda\")\n",
    "try:\n",
    "    net\n",
    "    print('net exists')\n",
    "except NameError:\n",
    "    net = LoFTR().to(device)\n",
    "    print('net does not exist')\n",
    "\n",
    "\n",
    "check_valid_input(splits)\n",
    "\n",
    "train = load_split(splits[0])\n",
    "train = filter_staticframe(train)\n",
    "test = load_split(splits[1])\n",
    "test = filter_staticframe(test)\n",
    "\n",
    "with open(\"train_files.txt\", \"w\") as f:\n",
    "    for line in train:\n",
    "        f.write(line+\"\\n\")\n",
    "\n",
    "with open(\"val_files.txt\", \"w\") as f:\n",
    "    for line in test:\n",
    "        f.write(line+\"\\n\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
