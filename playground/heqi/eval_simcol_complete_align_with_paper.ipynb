{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64534f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/workspace/heqi/mmcv/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading configs from results/simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6/models/configs.yml\n",
      "Loading  net_depth_encoder\n",
      "Loading  net_depth_decoder\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e62e2a785a643c6b33f68e357ca6e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e850c3403f7b4ddb8ed32969551824a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.9273208782100614\n",
      "Mean L1 error in cm:  0.20604080977766856\n",
      "Median relative error in %:  7.559314190791078\n",
      "Mean RMSE in cm:  0.38050338251165117\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.883 | std: 0.063\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0751  &  0.0358  &   0.379  &   0.114  &   0.941  &   0.984  &   0.994  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b525b8480a45a1bfa9c3fb6e8b4499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c230d3984a61462dae01bd33ae324d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.9256116461901716\n",
      "Mean L1 error in cm:  0.19810724932058527\n",
      "Median relative error in %:  7.381749242803481\n",
      "Mean RMSE in cm:  0.3709657609125051\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.887 | std: 0.064\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0852  &  0.0751  &   0.365  &   0.114  &   0.951  &   0.985  &   0.993  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e6e4762c334e9b934007424d9e5345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910f548897894d73b4cfbe1bf3676a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.9334419477979875\n",
      "Mean L1 error in cm:  0.20623960556540594\n",
      "Median relative error in %:  7.0295679762776055\n",
      "Mean RMSE in cm:  0.3852643472327582\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.891 | std: 0.061\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0829  &  0.0703  &   0.377  &   0.111  &   0.951  &   0.983  &   0.993  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939cfc6bb9784a66a5419cb74cc640e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2445fbfa201843dda6a1efdfaea33d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.9800665594719712\n",
      "Mean L1 error in cm:  0.19958204380228187\n",
      "Median relative error in %:  4.945063355796568\n",
      "Mean RMSE in cm:  0.37464329427410104\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.965 | std: 0.046\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0879  &  0.0972  &   0.378  &   0.109  &   0.959  &   0.984  &   0.992  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf442f4576f74efa9139da7d108d27f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c92809aa554012a1e0c2ab1db79816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.977140625041163\n",
      "Mean L1 error in cm:  0.2030935403150603\n",
      "Median relative error in %:  5.1143470545474425\n",
      "Mean RMSE in cm:  0.3758040395409566\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.962 | std: 0.039\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0849  &    0.13  &   0.383  &   0.102  &   0.962  &   0.992  &   0.996  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b8379192314dcbbd1613e15fb3df1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18bd059173545d8b66cba6d82571a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.9806199378599089\n",
      "Mean L1 error in cm:  0.201099068608611\n",
      "Median relative error in %:  5.042046068665545\n",
      "Mean RMSE in cm:  0.37425431952521343\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.961 | std: 0.039\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0685  &   0.044  &   0.383  &   0.105  &   0.958  &   0.989  &   0.995  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0310aff4e71549159adbe0773d6181f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa7abbdfc6a432ea4cd33ee32609ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.9684204969389127\n",
      "Mean L1 error in cm:  0.17445344385000056\n",
      "Median relative error in %:  3.9566294406650306\n",
      "Mean RMSE in cm:  0.3363537952778913\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.956 | std: 0.026\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0533  &  0.0276  &   0.353  &  0.0909  &   0.973  &   0.992  &   0.997  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68e0d5684f54f05b4091066984c836b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9731f2d0b91e4d7385949dfe7e21dd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.9666702856276023\n",
      "Mean L1 error in cm:  0.1759175063839009\n",
      "Median relative error in %:  4.04584563221887\n",
      "Mean RMSE in cm:  0.34646505766587177\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.954 | std: 0.025\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&   0.053  &  0.0272  &   0.362  &  0.0899  &   0.976  &   0.993  &   0.997  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e066da807437411bac7bc817cb98ba60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/595 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "-> Computing predictions with size 352x352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198837a37a2540b4bc86e04895677924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale:  0.966243955850548\n",
      "Mean L1 error in cm:  0.18336595379900353\n",
      "Median relative error in %:  4.3874391948073725\n",
      "Mean RMSE in cm:  0.352922362602129\n",
      "gt_width, gt_height 475 475\n",
      " Scaling ratios | med: 0.947 | std: 0.027\n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | \n",
      "&  0.0558  &  0.0282  &    0.37  &   0.091  &   0.974  &   0.994  &   0.997  \\\\\n",
      "\n",
      "-> Done!\n",
      "simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\n",
      "meds: 0.883  0.887  0.891  0.965  0.962  0.961  0.956  0.954  0.947  \n",
      "\n",
      "   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 |      med |      std | \n",
      "&  0.0754  &  0.0658  &   0.374  &   0.106  &   0.958  &   0.987  &   0.994  &    0.93  &  0.0468  \\\\\n",
      "\n",
      "-> Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/data/workspace/heqi/matchingloss\")\n",
    "from depthnet.utils import *\n",
    "from depthnet.model import EstimateDepth\n",
    "from pathlib import Path\n",
    "\n",
    "# path of model\n",
    "model_name = \"simcol_complete/RCC_cropalign_matching_depthnet_simcol_complete_monodepth2_rep6\"\n",
    "\n",
    "device = f'cuda:0'\n",
    "gpu_id = 0\n",
    "if gpu_id is not None:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "cfgs = load_yaml(Path(\"results\") / model_name / \"models\" / \"configs.yml\")\n",
    "cfgs.update({'device': device, \"not_load_nets\": [\"net_pose_encoder\", \"net_pose_decoder\"]})\n",
    "\n",
    "\n",
    "def getDepthNet():\n",
    "    cp_path = Path('results') / model_name / \"models\" / \"weights_last\"\n",
    "\n",
    "    model = EstimateDepth(cfgs)\n",
    "    \n",
    "    cp = {}\n",
    "    for network_name in model.network_names:\n",
    "        cp[network_name] = torch.load(cp_path / \"{}.pth\".format(network_name), map_location=device)\n",
    "\n",
    "    model.load_model_state(cp)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = getDepthNet()\n",
    "model.to_device(device)\n",
    "\n",
    "# load\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import collections\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "\n",
    "from depthnet.networks.layers import disp_to_depth\n",
    "from depthnet.utils import readlines\n",
    "import depthnet.datasets as datasets\n",
    "import depthnet.networks as networks\n",
    "from depthnet.datasets import C3VDDataset, SimcolDataset\n",
    "    \n",
    "exps = [cfgs[\"model_name\"]]\n",
    "\n",
    "modes = ['test_seperately/test_S_I_S5_files.txt',\n",
    "        'test_seperately/test_S_I_S15_files.txt',\n",
    "        'test_seperately/test_S_I_S10_files.txt',\n",
    "        'test_seperately/test_S_II_B5_files.txt',\n",
    "        'test_seperately/test_S_II_B15_files.txt',\n",
    "        'test_seperately/test_S_II_B10_files.txt',\n",
    "        'test_seperately/test_S_III_O1_files.txt',\n",
    "        'test_seperately/test_S_III_O2_files.txt',\n",
    "        'test_seperately/test_S_III_O3_files.txt']\n",
    "\n",
    "test_align_paper = []\n",
    "\n",
    "test_mean_errors = []\n",
    "meds = []\n",
    "stds = []\n",
    "masses = []\n",
    "\n",
    "warning1 = False\n",
    "warning2 = False\n",
    "\n",
    "\n",
    "for mode in modes:\n",
    "\n",
    "    gt_depths = []\n",
    "    split = cfgs.get('split')\n",
    "    fpath = os.path.join(\"splits\", split, \"{}\")\n",
    "    data_path = cfgs.get('data_path')\n",
    "    filenames = readlines(fpath.format(mode))\n",
    "    for line in tqdm(filenames):\n",
    "        folder, _, frame_id, _ = line.split()\n",
    "        frame_fpath = os.path.join(data_path, folder, \"{}{}\".format(frame_id.replace(\"FrameBuffer\", \"Depth\"), \".png\"))\n",
    "        gt_depth = cv2.imread(frame_fpath, -1)/(255*256)\n",
    "        gt_depths.append(gt_depth)\n",
    "        \n",
    "    gt_depths = np.array(gt_depths) * 20 # cm\n",
    "\n",
    "    print(cfgs[\"model_name\"])\n",
    "\n",
    "\n",
    "    num_workers = cfgs.get('num_workers', 4)\n",
    "    height = cfgs.get('height', 256)\n",
    "    width = cfgs.get('width', 320)\n",
    "    frame_ids = [0]\n",
    "    num_scales = 1\n",
    "    dataset = globals().get(cfgs.get('dataset', C3VDDataset))\n",
    "    split = cfgs.get('split')\n",
    "    fpath = os.path.join(\"splits\", split, \"{}\")\n",
    "    filenames = readlines(fpath.format(mode))\n",
    "    img_ext = '.png' if cfgs.get('png', False) else '.jpg'\n",
    "    matcher_result_load = None #np.load(cfgs.get('matcher_result', None), allow_pickle=True).all()\n",
    "\n",
    "    dataset = dataset(data_path, filenames, matcher_result_load,\n",
    "        height, width, frame_ids, num_scales,\n",
    "        is_train=False, img_ext=img_ext)\n",
    "    dataloader = DataLoader(dataset, 16, shuffle=False, num_workers=num_workers,\n",
    "                            pin_memory=True, drop_last=False)\n",
    "\n",
    "    model.set_eval()\n",
    "\n",
    "    pred_depths = []\n",
    "\n",
    "    print(\"-> Computing predictions with size {}x{}\".format(width, height))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            input_color = data[(\"color\", 0, 0)].to(device)\n",
    "\n",
    "            output = model.net_depth_decoder(model.net_depth_encoder(input_color))\n",
    "\n",
    "            _, pred_depth = disp_to_depth(output[(\"disp\", 0)], cfgs[\"min_depth\"], cfgs[\"max_depth\"])\n",
    "            pred_depth = pred_depth.cpu()[:, 0].numpy()\n",
    "            pred_depths.append(pred_depth)\n",
    "            \n",
    "    pred_depths = np.concatenate(pred_depths)\n",
    "\n",
    "    MIN_DEPTH = 0.001\n",
    "    MAX_DEPTH = 20.\n",
    "    errors = []\n",
    "    ratios = []\n",
    "\n",
    "    def compute_errors(gt, pred):\n",
    "        thresh = np.maximum((gt / pred), (pred / gt))\n",
    "        a1 = (thresh < 1.25     ).mean()\n",
    "        a2 = (thresh < 1.25 ** 2).mean()\n",
    "        a3 = (thresh < 1.25 ** 3).mean()\n",
    "\n",
    "        rmse = (gt - pred) ** 2\n",
    "        rmse = np.sqrt(rmse.mean())\n",
    "\n",
    "        rmse_log = (np.log(gt) - np.log(pred)) ** 2\n",
    "        rmse_log = np.sqrt(rmse_log.mean())\n",
    "\n",
    "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
    "\n",
    "        sq_rel = np.mean(((gt - pred) ** 2) / gt)\n",
    "\n",
    "        return abs_rel, sq_rel, rmse, rmse_log, a1, a2, a3\n",
    "    \n",
    "    def eval_depth(pred, gt_depth):\n",
    "        L1_error = np.mean(np.abs(pred - gt_depth))\n",
    "        rel_error = np.median(np.abs((pred - gt_depth)/(gt_depth + 10e-5))) * 100\n",
    "        RMSE_error = np.sqrt(np.mean((pred - gt_depth)**2))\n",
    "        return L1_error, rel_error, RMSE_error\n",
    "    \n",
    "    gts_ = np.mean(np.mean(gt_depths, 1), 1)\n",
    "    preds_ = np.mean(np.mean(np.array(pred_depths), 1), 1)\n",
    "    scale = np.sum(preds_ * gts_) / np.sum(preds_ * preds_)  # monocular methods predict depth up to scale\n",
    "    print('Scale: ', scale)\n",
    "    L1_errors, rel_errors, rmses = [], [], []\n",
    "    \n",
    "    for i in range(pred_depths.shape[0]):\n",
    "        gt_depth = gt_depths[i]\n",
    "        gt_height, gt_width = gt_depth.shape[:2]\n",
    "        pred_depth = cv2.resize(pred_depths[i], (gt_width, gt_height)) * scale\n",
    "        \n",
    "        pred_depth[pred_depth < MIN_DEPTH] = MIN_DEPTH\n",
    "        pred_depth[pred_depth > MAX_DEPTH] = MAX_DEPTH\n",
    "        \n",
    "        L1_error, rel_error, rmse = eval_depth(pred_depth, gt_depth)\n",
    "        L1_errors.append(L1_error)\n",
    "        rel_errors.append(rel_error)\n",
    "        rmses.append(rmse)\n",
    "        \n",
    "    print('Mean L1 error in cm: ', np.mean(L1_errors))\n",
    "    print('Median relative error in %: ', np.mean(rel_errors))\n",
    "    print('Mean RMSE in cm: ', np.mean(rmses))\n",
    "    \n",
    "    test_align_paper.append([np.mean(L1_errors), np.mean(rel_errors), np.mean(rmses)])\n",
    "\n",
    "    for i in range(pred_depths.shape[0]):\n",
    "        gt_depth = gt_depths[i]\n",
    "        gt_height, gt_width = gt_depth.shape[:2]\n",
    "\n",
    "        pred_depth = pred_depths[i]\n",
    "        pred_depth = cv2.resize(pred_depth, (gt_width, gt_height))\n",
    "\n",
    "        mask = gt_depth > 0\n",
    "\n",
    "        pred_depth = pred_depth[mask]\n",
    "        gt_depth = gt_depth[mask]\n",
    "\n",
    "        ratio = np.median(gt_depth) / np.median(pred_depth)\n",
    "        ratios.append(ratio)\n",
    "        pred_depth *= ratio\n",
    "\n",
    "        pred_depth[pred_depth < MIN_DEPTH] = MIN_DEPTH\n",
    "        pred_depth[pred_depth > MAX_DEPTH] = MAX_DEPTH\n",
    "\n",
    "        errors.append(compute_errors(gt_depth, pred_depth))\n",
    "\n",
    "    print(\"gt_width, gt_height\", gt_width, gt_height)\n",
    "\n",
    "    ratios = np.array(ratios)\n",
    "    med = np.median(ratios)\n",
    "    print(\" Scaling ratios | med: {:0.3f} | std: {:0.3f}\".format(med, np.std(ratios / med)))\n",
    "\n",
    "    mean_errors = np.array(errors).mean(0)\n",
    "\n",
    "    print(\"\\n  \" + (\"{:>8} | \" * 7).format(\"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\"))\n",
    "    print((\"&{: 8.3}  \" * 7).format(*mean_errors.tolist()) + \"\\\\\\\\\")\n",
    "    print(\"\\n-> Done!\")\n",
    "    \n",
    "    test_mean_errors.append(mean_errors)\n",
    "    meds.append(med)\n",
    "    stds.append(np.std(ratios / med))\n",
    "    masses.append(len(dataset))\n",
    "\n",
    "print(cfgs[\"model_name\"])\n",
    "print(\"meds: \" + (\"{:0.3f}  \" * len(meds)).format(*meds))\n",
    "mean_med = np.sum([mass * med for mass, med in zip(masses, meds)]) / np.sum(masses)\n",
    "# print(\"mean med: \" + (\"{:0.3f}\").format(mean_med))\n",
    "mean_std = np.sum([mass * std for mass, std in zip(masses, stds)]) / np.sum(masses)\n",
    "# print(\"mean std: {}\".format(mean_std))\n",
    "total_mean_errors = np.sum([mass * mean_errors for mass, mean_errors in zip(masses, test_mean_errors)], axis=0) / np.sum(masses)\n",
    "\n",
    "\n",
    "print(\"\\n  \" + (\"{:>8} | \" * 9).format(\"abs_rel\", \"sq_rel\", \"rmse\", \"rmse_log\", \"a1\", \"a2\", \"a3\", \"med\", \"std\"))\n",
    "print((\"&{: 8.3}  \" * 7).format(*total_mean_errors.tolist()) + \"&{: 8.3}  &{: 8.3}  \".format(mean_med, mean_std) + \"\\\\\\\\\")\n",
    "print(\"\\n-> Done!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6fc6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
